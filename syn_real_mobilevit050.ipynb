{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+fTtSeZQImozjoFcyCx9J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Htets-Corner/SYNTHBUSTER_RAISE-1k/blob/main/syn_real_mobilevit050.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjolD0h7Lxet",
        "outputId": "0a51a7bc-b401-4854-be74-cff87cbc63ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train path: /content/drive/MyDrive/Dataset/train\n",
            "Test path: /content/drive/MyDrive/Dataset/test\n",
            "Classes: ['ai', 'real']\n",
            "Train size: 3199\n",
            "Test size: 800\n"
          ]
        }
      ],
      "source": [
        "# Step 0: Data Preparation\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define dataset path\n",
        "import os\n",
        "\n",
        "# Update this path if needed\n",
        "dataset_path = \"/content/drive/MyDrive/Dataset\"\n",
        "\n",
        "train_dir = os.path.join(dataset_path, \"train\")\n",
        "test_dir  = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "print(\"Train path:\", train_dir)\n",
        "print(\"Test path:\", test_dir)\n",
        "\n",
        "# 3. Import necessary libraries\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 4. Define image transformations (resize, normalization)\n",
        "# MobileViT usually works with 256x256 or 224x224 input\n",
        "image_size = 256\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],   # normalize to [-1, 1]\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "\n",
        "# 5. Load train and test datasets\n",
        "#train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "#test_dataset  = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.PNG', '.bmp', '.tif', '.tiff', '.webp')\n",
        "\n",
        "train_dataset = ImageFolder(\n",
        "    root=train_dir,\n",
        "    transform=transform,\n",
        "    is_valid_file=lambda path: path.lower().endswith(valid_exts)\n",
        ")\n",
        "\n",
        "test_dataset = ImageFolder(\n",
        "    root=test_dir,\n",
        "    transform=transform,\n",
        "    is_valid_file=lambda path: path.lower().endswith(valid_exts)\n",
        ")\n",
        "\n",
        "\n",
        "# 6. Create DataLoaders\n",
        "#batch_size = 32\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# 7. Check class labels\n",
        "classes = train_dataset.classes\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Train size:\", len(train_dataset))\n",
        "print(\"Test size:\", len(test_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Train/AI files:\", len(os.listdir(train_dir + \"/ai\")))\n",
        "print(\"Train/Real files:\", len(os.listdir(train_dir + \"/real\")))\n",
        "print(\"Test/AI files:\", len(os.listdir(test_dir + \"/ai\")))\n",
        "print(\"Test/Real files:\", len(os.listdir(test_dir + \"/real\")))\n",
        "\n",
        "# Show first 5 files in each folder\n",
        "print(\"Sample AI:\", os.listdir(train_dir + \"/ai\")[:5])\n",
        "print(\"Sample Real:\", os.listdir(train_dir + \"/real\")[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQFeCGAWPZgk",
        "outputId": "750d1757-0b6d-4d7c-c745-b72adc3d1092"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/AI files: 2400\n",
            "Train/Real files: 799\n",
            "Test/AI files: 600\n",
            "Test/Real files: 200\n",
            "Sample AI: ['stable-diffusion-2_r179bb406t.png', 'stable-diffusion-2_r0e965ba7t.png', 'firefly_r03f70ccdt.png', 'stable-diffusion-xl_r164c1e13t.png', 'firefly_r138ad247t.png']\n",
            "Sample Real: ['r15c91802t.png', 'r0db6cc31t.png', 'r1aa53167t.png', 'r05d9d749t.png', 'r13de1e12t.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this first cell in Colab\n",
        "!pip install -q timm        # recommended: timm includes MobileViT variants + pretrained weights\n",
        "# optional fallback (if you want the standalone implementation)\n",
        "# !pip install -q git+https://github.com/chinhsuanwu/mobilevit-pytorch.git\n"
      ],
      "metadata": {
        "id": "43lk34l8TnSH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import timm\n",
        "from collections import Counter\n",
        "print(\"Torch:\", torch.__version__, \"Timm:\", timm.__version__)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1siAATATu7T",
        "outputId": "74eb8ec7-e3c0-4af3-ea51-8886b29ea8e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 Timm: 1.0.19\n",
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list available MobileViT-like models in timm\n",
        "models = timm.list_models('*mobilevit*')\n",
        "print(\"MobileViT variants found in timm:\", models)\n",
        "\n",
        "# choose one automatically (you can change this name)\n",
        "if len(models) == 0:\n",
        "    raise RuntimeError(\"No MobileViT models found in timm. You can pip-install a standalone MobileViT repo instead.\")\n",
        "model_name = models[0]   # default to first found; or set e.g. 'mobilevit_xxs' or 'mobilevit_s'\n",
        "print(\"Using model:\", model_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWDUv5ieT3MM",
        "outputId": "17138ec5-5e53-449d-fbbb-9f333512f980"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileViT variants found in timm: ['mobilevit_s', 'mobilevit_xs', 'mobilevit_xxs', 'mobilevitv2_050', 'mobilevitv2_075', 'mobilevitv2_100', 'mobilevitv2_125', 'mobilevitv2_150', 'mobilevitv2_175', 'mobilevitv2_200']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Choose model\n",
        "model_name = \"mobilevitv2_050\"\n",
        "\n",
        "# 2. Load pretrained model from timm\n",
        "model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "# 3. Adapt classifier head for 2 classes (ai, real)\n",
        "if hasattr(model, \"reset_classifier\"):\n",
        "    model.reset_classifier(num_classes=2)\n",
        "else:\n",
        "    # fallback if reset_classifier not available\n",
        "    in_features = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(in_features, 2)\n",
        "\n",
        "# 4. Move to device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(f\"âœ… Loaded {model_name} with classifier reset to 2 classes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUYQ5RZUdfY",
        "outputId": "b496f0a0-2b7a-42a2-93d8-560a2f6dc277"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded mobilevitv2_050 with classifier reset to 2 classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 1) Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -------------------------------\n",
        "# 2) Dataset & DataLoader (reuse your train_dataset and test_dataset)\n",
        "# Handle class imbalance with WeightedRandomSampler\n",
        "targets = [s[1] for s in train_dataset.samples]\n",
        "counts = Counter(targets)\n",
        "class_weights = {cls: 1.0 / count for cls, count in counts.items()}\n",
        "sample_weights = [class_weights[t] for t in targets]\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 3) Loss, optimizer, scheduler\n",
        "criterion = nn.CrossEntropyLoss()  # class indices 0/1\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)  # adjust T_max for epochs\n",
        "\n",
        "# Mixed precision\n",
        "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "# -------------------------------\n",
        "# 4) Train & Validation functions\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += images.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, scaler=None):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    loop = tqdm(loader, desc=\"Train\")\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        if scaler is not None:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += images.size(0)\n",
        "        loop.set_postfix(loss=running_loss/total, acc=100*correct/total)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "# -------------------------------\n",
        "# 5) Training loop with metrics storage\n",
        "num_epochs = 10\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "save_path = \"/content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\"\n",
        "\n",
        "# Lists to store metrics per epoch\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler)\n",
        "    # Validate\n",
        "    val_loss, val_acc = validate(model, test_loader)\n",
        "    # Scheduler step\n",
        "    scheduler.step()\n",
        "\n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'best_acc': best_acc\n",
        "        }, save_path)\n",
        "        print(f\"ðŸ’¾ Best model saved: {save_path}\")\n",
        "\n",
        "# Load best weights at the end\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(\"âœ… Training complete, best model loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jxtHJyJdVQq",
        "outputId": "7bb682a5-7bfa-4ce4-bfed-270d2303541e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:24<00:00, 21.24s/it, acc=75.2, loss=0.552]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: Train Loss 0.5524 Acc 0.7518 | Val Loss 0.2921 Acc 0.8888\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:20<00:00, 20.61s/it, acc=92.8, loss=0.19]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: Train Loss 0.1897 Acc 0.9281 | Val Loss 0.1341 Acc 0.9437\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:12<00:00, 21.13s/it, acc=96.2, loss=0.106]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10: Train Loss 0.1063 Acc 0.9619 | Val Loss 0.1213 Acc 0.9500\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:28<00:00, 20.68s/it, acc=98, loss=0.0652]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10: Train Loss 0.0652 Acc 0.9803 | Val Loss 0.1173 Acc 0.9487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:34<00:00, 20.74s/it, acc=98.1, loss=0.0603]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10: Train Loss 0.0603 Acc 0.9806 | Val Loss 0.1065 Acc 0.9563\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:50<00:00, 20.91s/it, acc=98.7, loss=0.0398]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10: Train Loss 0.0398 Acc 0.9869 | Val Loss 0.1091 Acc 0.9587\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  13%|â–ˆâ–Ž        | 13/100 [05:26<33:13, 22.91s/it, acc=98.6, loss=0.0566]"
          ]
        }
      ]
    }
  ]
}