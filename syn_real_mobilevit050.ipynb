{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Htets-Corner/SYNTHBUSTER_RAISE-1k/blob/main/syn_real_mobilevit050.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjolD0h7Lxet",
        "outputId": "0a51a7bc-b401-4854-be74-cff87cbc63ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train path: /content/drive/MyDrive/Dataset/train\n",
            "Test path: /content/drive/MyDrive/Dataset/test\n",
            "Classes: ['ai', 'real']\n",
            "Train size: 3199\n",
            "Test size: 800\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Step 0: Data Preparation\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define dataset path\n",
        "import os\n",
        "\n",
        "# Update this path if needed\n",
        "dataset_path = \"/content/drive/MyDrive/Dataset\"\n",
        "\n",
        "train_dir = os.path.join(dataset_path, \"train\")\n",
        "test_dir  = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "print(\"Train path:\", train_dir)\n",
        "print(\"Test path:\", test_dir)\n",
        "\n",
        "# 3. Import necessary libraries\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 4. Define image transformations (resize, normalization)\n",
        "# MobileViT usually works with 256x256 or 224x224 input\n",
        "image_size = 256\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.5, 0.5, 0.5],   # normalize to [-1, 1]\n",
        "        std=[0.5, 0.5, 0.5]\n",
        "    )\n",
        "])\n",
        "\n",
        "# 5. Load train and test datasets\n",
        "#train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "#test_dataset  = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.PNG', '.bmp', '.tif', '.tiff', '.webp')\n",
        "\n",
        "train_dataset = ImageFolder(\n",
        "    root=train_dir,\n",
        "    transform=transform,\n",
        "    is_valid_file=lambda path: path.lower().endswith(valid_exts)\n",
        ")\n",
        "\n",
        "test_dataset = ImageFolder(\n",
        "    root=test_dir,\n",
        "    transform=transform,\n",
        "    is_valid_file=lambda path: path.lower().endswith(valid_exts)\n",
        ")\n",
        "\n",
        "\n",
        "# 6. Create DataLoaders\n",
        "#batch_size = 32\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# 7. Check class labels\n",
        "classes = train_dataset.classes\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Train size:\", len(train_dataset))\n",
        "print(\"Test size:\", len(test_dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQFeCGAWPZgk",
        "outputId": "750d1757-0b6d-4d7c-c745-b72adc3d1092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train/AI files: 2400\n",
            "Train/Real files: 799\n",
            "Test/AI files: 600\n",
            "Test/Real files: 200\n",
            "Sample AI: ['stable-diffusion-2_r179bb406t.png', 'stable-diffusion-2_r0e965ba7t.png', 'firefly_r03f70ccdt.png', 'stable-diffusion-xl_r164c1e13t.png', 'firefly_r138ad247t.png']\n",
            "Sample Real: ['r15c91802t.png', 'r0db6cc31t.png', 'r1aa53167t.png', 'r05d9d749t.png', 'r13de1e12t.png']\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import os\n",
        "\n",
        "print(\"Train/AI files:\", len(os.listdir(train_dir + \"/ai\")))\n",
        "print(\"Train/Real files:\", len(os.listdir(train_dir + \"/real\")))\n",
        "print(\"Test/AI files:\", len(os.listdir(test_dir + \"/ai\")))\n",
        "print(\"Test/Real files:\", len(os.listdir(test_dir + \"/real\")))\n",
        "\n",
        "# Show first 5 files in each folder\n",
        "print(\"Sample AI:\", os.listdir(train_dir + \"/ai\")[:5])\n",
        "print(\"Sample Real:\", os.listdir(train_dir + \"/real\")[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "43lk34l8TnSH"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# Run this first cell in Colab\n",
        "!pip install -q timm        # recommended: timm includes MobileViT variants + pretrained weights\n",
        "# optional fallback (if you want the standalone implementation)\n",
        "# !pip install -q git+https://github.com/chinhsuanwu/mobilevit-pytorch.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1siAATATu7T",
        "outputId": "74eb8ec7-e3c0-4af3-ea51-8886b29ea8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch: 2.8.0+cu126 Timm: 1.0.19\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import timm\n",
        "from collections import Counter\n",
        "print(\"Torch:\", torch.__version__, \"Timm:\", timm.__version__)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWDUv5ieT3MM",
        "outputId": "17138ec5-5e53-449d-fbbb-9f333512f980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MobileViT variants found in timm: ['mobilevit_s', 'mobilevit_xs', 'mobilevit_xxs', 'mobilevitv2_050', 'mobilevitv2_075', 'mobilevitv2_100', 'mobilevitv2_125', 'mobilevitv2_150', 'mobilevitv2_175', 'mobilevitv2_200']\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# list available MobileViT-like models in timm\n",
        "models = timm.list_models('*mobilevit*')\n",
        "print(\"MobileViT variants found in timm:\", models)\n",
        "\n",
        "# choose one automatically (you can change this name)\n",
        "if len(models) == 0:\n",
        "    raise RuntimeError(\"No MobileViT models found in timm. You can pip-install a standalone MobileViT repo instead.\")\n",
        "model_name = models[0]   # default to first found; or set e.g. 'mobilevit_xxs' or 'mobilevit_s'\n",
        "print(\"Using model:\", model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQUYQ5RZUdfY",
        "outputId": "b496f0a0-2b7a-42a2-93d8-560a2f6dc277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded mobilevitv2_050 with classifier reset to 2 classes\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Choose model\n",
        "model_name = \"mobilevitv2_050\"\n",
        "\n",
        "# 2. Load pretrained model from timm\n",
        "model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "# 3. Adapt classifier head for 2 classes (ai, real)\n",
        "if hasattr(model, \"reset_classifier\"):\n",
        "    model.reset_classifier(num_classes=2)\n",
        "else:\n",
        "    # fallback if reset_classifier not available\n",
        "    in_features = model.classifier.in_features\n",
        "    model.classifier = nn.Linear(in_features, 2)\n",
        "\n",
        "# 4. Move to device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(f\"âœ… Loaded {model_name} with classifier reset to 2 classes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "collapsed": true,
        "id": "2jxtHJyJdVQq",
        "outputId": "7bb682a5-7bfa-4ce4-bfed-270d2303541e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:24<00:00, 21.24s/it, acc=75.2, loss=0.552]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: Train Loss 0.5524 Acc 0.7518 | Val Loss 0.2921 Acc 0.8888\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:20<00:00, 20.61s/it, acc=92.8, loss=0.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: Train Loss 0.1897 Acc 0.9281 | Val Loss 0.1341 Acc 0.9437\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:12<00:00, 21.13s/it, acc=96.2, loss=0.106]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: Train Loss 0.1063 Acc 0.9619 | Val Loss 0.1213 Acc 0.9500\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:28<00:00, 20.68s/it, acc=98, loss=0.0652]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: Train Loss 0.0652 Acc 0.9803 | Val Loss 0.1173 Acc 0.9487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:34<00:00, 20.74s/it, acc=98.1, loss=0.0603]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: Train Loss 0.0603 Acc 0.9806 | Val Loss 0.1065 Acc 0.9563\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:50<00:00, 20.91s/it, acc=98.7, loss=0.0398]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: Train Loss 0.0398 Acc 0.9869 | Val Loss 0.1091 Acc 0.9587\n",
            "ðŸ’¾ Best model saved: /content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [35:51<00:00, 21.52s/it, acc=98.5, loss=0.0437]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: Train Loss 0.0437 Acc 0.9853 | Val Loss 0.1188 Acc 0.9575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/100 [00:50<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3087866873.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3087866873.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, scaler)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# 1) Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -------------------------------\n",
        "# 2) Dataset & DataLoader (reuse your train_dataset and test_dataset)\n",
        "# Handle class imbalance with WeightedRandomSampler\n",
        "targets = [s[1] for s in train_dataset.samples]\n",
        "counts = Counter(targets)\n",
        "class_weights = {cls: 1.0 / count for cls, count in counts.items()}\n",
        "sample_weights = [class_weights[t] for t in targets]\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 3) Loss, optimizer, scheduler\n",
        "criterion = nn.CrossEntropyLoss()  # class indices 0/1\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)  # adjust T_max for epochs\n",
        "\n",
        "# Mixed precision\n",
        "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "# -------------------------------\n",
        "# 4) Train & Validation functions\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += images.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, scaler=None):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    loop = tqdm(loader, desc=\"Train\")\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        if scaler is not None:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += images.size(0)\n",
        "        loop.set_postfix(loss=running_loss/total, acc=100*correct/total)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "# -------------------------------\n",
        "# 5) Training loop with metrics storage\n",
        "num_epochs = 10\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "save_path = \"/content/drive/MyDrive/Dataset/mobilevitv2_050_best.pth\"\n",
        "\n",
        "# Lists to store metrics per epoch\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler)\n",
        "    # Validate\n",
        "    val_loss, val_acc = validate(model, test_loader)\n",
        "    # Scheduler step\n",
        "    scheduler.step()\n",
        "\n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss {train_loss:.4f} Acc {train_acc:.4f} | Val Loss {val_loss:.4f} Acc {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'best_acc': best_acc\n",
        "        }, save_path)\n",
        "        print(f\"ðŸ’¾ Best model saved: {save_path}\")\n",
        "\n",
        "# Load best weights at the end\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(\"âœ… Training complete, best model loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLvuHKU2ykNK",
        "outputId": "b8b98206-c8d3-47e3-a5e4-d216c5e65239",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Root: /content/drive/MyDrive/synthbuster_dataset\n",
            "Found folders: ['dalle3', 'firefly', 'raise', 'stable-diffusion-xl']\n",
            "AI generators detected: ['dalle3', 'firefly', 'stable-diffusion-xl']\n",
            "Real folder: True /content/drive/MyDrive/synthbuster_dataset/raise\n"
          ]
        }
      ],
      "source": [
        "# @title (RUN) Mount Drive and inspect dataset, list generators\n",
        "# Colab cell 1: mount drive and show dataset structure\n",
        "from pathlib import Path\n",
        "import random, shutil, os\n",
        "from collections import defaultdict\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT = Path(\"/content/drive/MyDrive/synthbuster_dataset\")  # <-- change if different\n",
        "if not ROOT.exists():\n",
        "    raise RuntimeError(f\"Path not found: {ROOT}\")\n",
        "\n",
        "print(\"Root:\", ROOT)\n",
        "children = [p.name for p in sorted(ROOT.iterdir()) if p.is_dir()]\n",
        "print(\"Found folders:\", children)\n",
        "\n",
        "# Expecting: raise (real), stable-diffusion-xl, dalle3, firefly (names may vary)\n",
        "ai_generators = [p.name for p in ROOT.iterdir() if p.is_dir() and p.name.lower() != \"raise\"]\n",
        "real_folder = ROOT / \"raise\"\n",
        "print(\"AI generators detected:\", ai_generators)\n",
        "print(\"Real folder:\", real_folder.exists(), real_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m30HtlYVKlq6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Utilities: valid ext, preprocessing & attack functions\n",
        "# Colab cell 2: utilities (image ext, laplacian preprocessing, attack functions)\n",
        "from PIL import Image, ImageFilter, ImageOps\n",
        "import numpy as np\n",
        "import io, random\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp', '.PNG')\n",
        "\n",
        "def is_image_file(p: Path):\n",
        "    return p.suffix.lower() in valid_exts\n",
        "\n",
        "# Optional Laplacian enhancement: apply and blend with original to emphasize high-frequency details\n",
        "def apply_laplacian_pil(pil_img, blend=0.5):\n",
        "    # pil_img: RGB PIL.Image\n",
        "    np_im = np.array(pil_img.convert(\"L\"))  # grayscale\n",
        "    lap = cv2.Laplacian(np_im, cv2.CV_64F)\n",
        "    lap = np.clip(np.abs(lap), 0, 255).astype(np.uint8)\n",
        "    lap = Image.fromarray(lap).convert(\"RGB\")\n",
        "    # blend with original\n",
        "    blended = Image.blend(pil_img, lap, alpha=blend)\n",
        "    return blended\n",
        "\n",
        "# Attack functions: inputs PIL.Image -> output PIL.Image\n",
        "def attack_crop(pil_img, min_frac=0.05, max_frac=0.20):\n",
        "    w, h = pil_img.size\n",
        "    frac = random.uniform(min_frac, max_frac)\n",
        "    area = w * h\n",
        "    remove_area = int(area * frac)\n",
        "    # remove a random rectangle of approx remove_area area (keep aspect ratio near original)\n",
        "    rw = int((remove_area / h)**0.5 * w/h * h) if h>0 else int(w*0.1)\n",
        "    # simplest: crop randomly some percentage from edges\n",
        "    crop_w = int(w * (1 - random.uniform(0.05, frac+0.05)))\n",
        "    crop_h = int(h * (1 - random.uniform(0.05, frac+0.05)))\n",
        "    crop_w = max(1, min(w, crop_w))\n",
        "    crop_h = max(1, min(h, crop_h))\n",
        "    x0 = random.randint(0, w-crop_w)\n",
        "    y0 = random.randint(0, h-crop_h)\n",
        "    cropped = pil_img.crop((x0, y0, x0 + crop_w, y0 + crop_h))\n",
        "    # resize back to original size\n",
        "    return cropped.resize((w,h), resample=Image.BILINEAR)\n",
        "\n",
        "def attack_blur(pil_img, kmin=3, kmax=9):\n",
        "    # gaussian blur via PIL.ImageFilter.GaussianBlur; radius ~ kernel/2\n",
        "    k = random.choice([3,5,7,9])\n",
        "    radius = k/2.0\n",
        "    return pil_img.filter(ImageFilter.GaussianBlur(radius=radius))\n",
        "\n",
        "def attack_noise(pil_img, var_min=5, var_max=20):\n",
        "    arr = np.array(pil_img).astype(np.float32)\n",
        "    var = random.uniform(var_min, var_max)\n",
        "    sigma = var**0.5\n",
        "    noise = np.random.normal(0, sigma, arr.shape)\n",
        "    noisy = arr + noise\n",
        "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
        "    return Image.fromarray(noisy)\n",
        "\n",
        "def attack_jpeg(pil_img, qmin=25, qmax=90):\n",
        "    q = random.randint(qmin, qmax)\n",
        "    buf = io.BytesIO()\n",
        "    pil_img.save(buf, format='JPEG', quality=q)\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf).convert(\"RGB\")\n",
        "\n",
        "def attack_combination(pil_img):\n",
        "    # random combination of 2-3 attacks\n",
        "    img = pil_img\n",
        "    choices = [attack_crop, attack_blur, attack_noise, attack_jpeg]\n",
        "    ops = random.sample(choices, k=random.randint(1,3))\n",
        "    for op in ops:\n",
        "        img = op(img)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) Already have train/test splits for leave-one-out\n",
        "# Colab cell 3 (updated): create per-run train/test splits for leave-one-out (skip if already exists)\n",
        "from pathlib import Path\n",
        "import random, shutil\n",
        "\n",
        "ROOT = Path(\"/content/drive/MyDrive/synthbuster_dataset\")\n",
        "OUT_ROOT = Path(\"/content/drive/MyDrive/synthbuster_runs\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ai_gens = [p.name for p in ROOT.iterdir() if p.is_dir() and p.name.lower() != \"raise\"]\n",
        "real_dir = ROOT / \"raise\"\n",
        "assert real_dir.exists(), \"real folder 'raise' not found.\"\n",
        "\n",
        "# Settings\n",
        "TEST_RATIO_REAL = 0.20\n",
        "TEST_RATIO_NON_HOLDOUT = 0.20\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "\n",
        "def is_image_file(p):\n",
        "    return p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\"]\n",
        "\n",
        "def make_leave_one_out_dirs(held_out_gen_name):\n",
        "    run_name = f\"leave_one_out_{held_out_gen_name}\"\n",
        "    run_root = OUT_ROOT / run_name\n",
        "    train_root = run_root / \"train\"\n",
        "    test_root = run_root / \"test\"\n",
        "\n",
        "    # âœ… Check if already created (train & test have data)\n",
        "    if train_root.exists() and test_root.exists():\n",
        "        num_train = sum(1 for _ in train_root.rglob(\"*\") if is_image_file(_))\n",
        "        num_test = sum(1 for _ in test_root.rglob(\"*\") if is_image_file(_))\n",
        "        if num_train > 0 and num_test > 0:\n",
        "            print(f\"âœ… Skipping {run_name}: already has train/test splits ({num_train} train, {num_test} test)\")\n",
        "            return run_root, train_root, test_root\n",
        "\n",
        "    # âŒ Otherwise recreate fresh\n",
        "    if run_root.exists():\n",
        "        shutil.rmtree(run_root)\n",
        "    train_root.mkdir(parents=True)\n",
        "    test_root.mkdir(parents=True)\n",
        "\n",
        "    # ---- Real images ----\n",
        "    real_images = [p for p in real_dir.rglob(\"*\") if is_image_file(p)]\n",
        "    random.shuffle(real_images)\n",
        "    n_real_test = max(1, int(len(real_images) * TEST_RATIO_REAL))\n",
        "    real_test = set(real_images[:n_real_test])\n",
        "    real_train = set(real_images[n_real_test:])\n",
        "\n",
        "    (train_root / \"raise\").mkdir(parents=True, exist_ok=True)\n",
        "    (test_root  / \"raise\").mkdir(parents=True, exist_ok=True)\n",
        "    for p in real_train:\n",
        "        shutil.copy2(p, train_root / \"raise\" / p.name)\n",
        "    for p in real_test:\n",
        "        shutil.copy2(p, test_root / \"raise\" / p.name)\n",
        "\n",
        "    # ---- AI generators ----\n",
        "    for gen in ai_gens:\n",
        "        target_train_cls = train_root / \"ai\"\n",
        "        target_test_cls = test_root / \"ai\"\n",
        "        target_train_cls.mkdir(parents=True, exist_ok=True)\n",
        "        target_test_cls.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        imgs = [p for p in (ROOT / gen).rglob(\"*\") if is_image_file(p)]\n",
        "        random.shuffle(imgs)\n",
        "\n",
        "        if gen == held_out_gen_name:\n",
        "            for p in imgs:\n",
        "                shutil.copy2(p, test_root / \"ai\" / f\"{gen}__{p.name}\")\n",
        "        else:\n",
        "            n_test = int(len(imgs) * TEST_RATIO_NON_HOLDOUT)\n",
        "            test_part = imgs[:n_test]\n",
        "            train_part = imgs[n_test:]\n",
        "            for p in train_part:\n",
        "                shutil.copy2(p, train_root / \"ai\" / f\"{gen}__{p.name}\")\n",
        "            for p in test_part:\n",
        "                shutil.copy2(p, test_root / \"ai\" / f\"{gen}__{p.name}\")\n",
        "\n",
        "    num_train = sum(1 for _ in train_root.rglob(\"*\") if is_image_file(_))\n",
        "    num_test = sum(1 for _ in test_root.rglob(\"*\") if is_image_file(_))\n",
        "    print(f\"âœ… Created {run_name}: {num_train} train, {num_test} test\")\n",
        "    return run_root, train_root, test_root\n",
        "\n",
        "# ---- Run for all AI generators ----\n",
        "run_roots = {}\n",
        "for held in ai_gens:\n",
        "    rr, tr, te = make_leave_one_out_dirs(held)\n",
        "    run_roots[held] = rr\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J6oabIWjSOXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09736fbf-6dd5-4437-a640-314f0e655124"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Skipping leave_one_out_dalle3: already has train/test splits (1040 train, 359 test)\n",
            "âœ… Skipping leave_one_out_firefly: already has train/test splits (1040 train, 359 test)\n",
            "âœ… Skipping leave_one_out_stable-diffusion-xl: already has train/test splits (960 train, 439 test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUPQNc2EK4Mp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title (NOT RUN) Already have train/test splits for leave-one-out\n",
        "# Colab cell 3: create per-run train/test splits for leave-one-out (one held-out generator)\n",
        "from pathlib import Path\n",
        "import random, shutil\n",
        "ROOT = Path(\"/content/drive/MyDrive/synthbuster_dataset\")\n",
        "OUT_ROOT = Path(\"/content/drive/MyDrive/synthbuster_runs\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ai_gens = [p.name for p in ROOT.iterdir() if p.is_dir() and p.name.lower() != \"raise\"]\n",
        "real_dir = ROOT / \"raise\"\n",
        "assert real_dir.exists(), \"real folder 'raise' not found.\"\n",
        "\n",
        "# Settings\n",
        "TEST_RATIO_REAL = 0.20  # fraction of real images reserved to test for each run\n",
        "TEST_RATIO_NON_HOLDOUT = 0.20  # for non-held-out AI generators we can still reserve some val images\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "\n",
        "def make_leave_one_out_dirs(held_out_gen_name):\n",
        "    run_name = f\"leave_one_out_{held_out_gen_name}\"\n",
        "    run_root = OUT_ROOT / run_name\n",
        "    if run_root.exists():\n",
        "        shutil.rmtree(run_root)  # start fresh\n",
        "    train_root = run_root / \"train\"\n",
        "    test_root = run_root / \"test\"\n",
        "    train_root.mkdir(parents=True)\n",
        "    test_root.mkdir(parents=True)\n",
        "\n",
        "    # 1) Real images -> split into train/test (test real subset goes to test set)\n",
        "    real_images = [p for p in real_dir.rglob(\"*\") if is_image_file(p)]\n",
        "    random.shuffle(real_images)\n",
        "    n_real_test = max(1, int(len(real_images) * TEST_RATIO_REAL))\n",
        "    real_test = set(real_images[:n_real_test])\n",
        "    real_train = set(real_images[n_real_test:])\n",
        "\n",
        "    # copy real\n",
        "    (train_root / \"raise\").mkdir(parents=True, exist_ok=True)\n",
        "    (test_root  / \"raise\").mkdir(parents=True, exist_ok=True)\n",
        "    for p in real_train:\n",
        "        shutil.copy2(p, train_root / \"raise\" / p.name)\n",
        "    for p in real_test:\n",
        "        shutil.copy2(p, test_root / \"raise\" / p.name)\n",
        "\n",
        "    # 2) AI generators: for held-out generator -> ALL go to test folder (as AI class)\n",
        "    for gen in ai_gens:\n",
        "        gen_dir = ROOT / gen\n",
        "        target_train_cls = train_root / \"ai\"  # we combine all AI gens into one 'ai' class for training\n",
        "        target_test_cls  = test_root  / \"ai\"\n",
        "        target_train_cls.mkdir(parents=True, exist_ok=True)\n",
        "        target_test_cls.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Copy AI images: held-out -> test; others -> train (with small val split optionally)\n",
        "    for gen in ai_gens:\n",
        "        gen_dir = ROOT / gen\n",
        "        imgs = [p for p in gen_dir.rglob(\"*\") if is_image_file(p)]\n",
        "        random.shuffle(imgs)\n",
        "        if gen == held_out_gen_name:\n",
        "            # all go to test\n",
        "            for p in imgs:\n",
        "                shutil.copy2(p, test_root / \"ai\" / f\"{gen}__{p.name}\")\n",
        "        else:\n",
        "            # non-heldout: split train/test (we'll mostly use train)\n",
        "            n_test = int(len(imgs) * TEST_RATIO_NON_HOLDOUT)\n",
        "            test_part = imgs[:n_test]\n",
        "            train_part = imgs[n_test:]\n",
        "            for p in train_part:\n",
        "                shutil.copy2(p, train_root / \"ai\" / f\"{gen}__{p.name}\")\n",
        "            for p in test_part:\n",
        "                shutil.copy2(p, test_root / \"ai\" / f\"{gen}__{p.name}\")\n",
        "\n",
        "    # sanity counts\n",
        "    def count_images(folder):\n",
        "        return sum(1 for f in folder.rglob(\"*\") if is_image_file(f))\n",
        "    print(f\"Run {run_name}: train size:\", count_images(train_root), \"test size:\", count_images(test_root))\n",
        "    return run_root, train_root, test_root\n",
        "\n",
        "# Example: create for all held-out ai generators\n",
        "run_roots = {}\n",
        "for held in ai_gens:\n",
        "    rr, tr, te = make_leave_one_out_dirs(held)\n",
        "    run_roots[held] = rr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWXjvMBnbKHP",
        "outputId": "2d86e02c-d921-44b3-826c-2000357815bb",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# @title (RUN) Install timm, imports, model factory (MobileViT-V2-100) and helper to adapt classifier\n",
        "# Colab cell 4: install timm, imports, model loader helper\n",
        "!pip install -q timm\n",
        "\n",
        "import timm\n",
        "import torch, torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import os, copy, math\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def create_mobilevitv2_100(num_classes, pretrained=True):\n",
        "    model = timm.create_model(\"mobilevitv2_100\", pretrained=pretrained)\n",
        "    # adapt classifier\n",
        "    try:\n",
        "        model.reset_classifier(num_classes=num_classes)\n",
        "    except Exception:\n",
        "        # fallback\n",
        "        if hasattr(model, \"classifier\"):\n",
        "            in_f = model.classifier.in_features\n",
        "            model.classifier = nn.Linear(in_f, num_classes)\n",
        "        elif hasattr(model, \"head\"):\n",
        "            in_f = model.head.in_features\n",
        "            model.head = nn.Linear(in_f, num_classes)\n",
        "        else:\n",
        "            raise RuntimeError(\"Cannot find classifier to replace\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tm7p2wPEbhx4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title (RUN) Train & evaluate function (single run). Uses two-LR, label smoothing, ReduceLROnPlateau, mixed precision\n",
        "# Colab cell 5: training loop function (one run)\n",
        "import os\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "def train_one_run(run_root: Path,\n",
        "                  image_size=256,\n",
        "                  batch_size=32,\n",
        "                  num_workers=2,\n",
        "                  num_epochs=30,\n",
        "                  laplacian_enhance=True,\n",
        "                  save_dir_base=\"/content/drive/MyDrive/synthbuster_runs_checkpoints\"):\n",
        "    print(f\"ðŸš€ Starting training in {run_root} with MobileViTv2_100 ...\")\n",
        "    run_root = Path(run_root)\n",
        "    train_dir = run_root / \"train\"\n",
        "    test_dir  = run_root / \"test\"\n",
        "    run_name = run_root.name\n",
        "    save_dir = Path(save_dir_base) / run_name\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "    best_model_path = save_dir / \"best_model.pth\"\n",
        "    last_checkpoint_path = save_dir / \"last_checkpoint.pth\"\n",
        "    csv_log_path = save_dir / \"training_log.csv\"\n",
        "\n",
        "    # transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(image_size, scale=(0.7,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.2,0.2,0.2,0.05),\n",
        "        transforms.RandomGrayscale(p=0.02),\n",
        "        transforms.ToTensor(),\n",
        "        # RandomErasing will be applied in training loop using torchvision.RandomErasing as transform\n",
        "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "    ])\n",
        "    # we will apply RandomErasing via dedicated transform\n",
        "    #train_transform.transforms.insert(4, transforms.RandomErasing(p=0.2, scale=(0.02,0.2), ratio=(0.3,3.3)))\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((image_size,image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
        "    ])\n",
        "\n",
        "    # datasets\n",
        "    train_dataset = datasets.ImageFolder(root=str(train_dir), transform=train_transform)\n",
        "    val_dataset = datasets.ImageFolder(root=str(test_dir), transform=val_transform)\n",
        "    classes = train_dataset.classes\n",
        "    print(\"Classes:\", classes)\n",
        "    num_classes = len(classes)\n",
        "\n",
        "    # sampler for class imbalance\n",
        "    targets = [s[1] for s in train_dataset.samples]\n",
        "    counts = Counter(targets)\n",
        "    class_weights = {cls: 1.0 / count for cls, count in counts.items()}\n",
        "    sample_weights = [class_weights[t] for t in targets]\n",
        "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,\n",
        "                              num_workers=num_workers, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                              num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    # model\n",
        "    model = create_mobilevitv2_100(num_classes=num_classes, pretrained=True)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # loss\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    # two-LR optimizer\n",
        "    backbone_params, head_params = [], []\n",
        "    for name, p in model.named_parameters():\n",
        "        if any(k in name.lower() for k in (\"classifier\",\"head\")):\n",
        "            head_params.append(p)\n",
        "        else:\n",
        "            backbone_params.append(p)\n",
        "\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': 5e-5},\n",
        "        {'params': head_params, 'lr': 2e-4}\n",
        "    ], weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "    scaler = GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "    # training bookkeeping\n",
        "    best_val_acc = 0.0\n",
        "    best_wts = copy.deepcopy(model.state_dict())\n",
        "    history = {\"epoch\":[],\"train_loss\":[],\"train_acc\":[],\"val_loss\":[],\"val_acc\":[],\"val_macro_f1\":[],\"val_bal_acc\":[]}\n",
        "\n",
        "    early_stopping_patience = 6\n",
        "    no_improve = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    # resume if exists\n",
        "    if last_checkpoint_path.exists():\n",
        "        print(\"Resuming from checkpoint:\", last_checkpoint_path)\n",
        "        ck = torch.load(last_checkpoint_path, map_location=device, weights_only=False)\n",
        "        model.load_state_dict(ck[\"model_state\"])\n",
        "        optimizer.load_state_dict(ck[\"optimizer_state\"])\n",
        "        history = ck[\"history\"]\n",
        "        start_epoch = ck[\"epoch\"]\n",
        "        best_val_acc = ck.get(\"best_val_acc\", 0.0)\n",
        "        print(f\"Resumed at epoch {start_epoch}, best_val_acc {best_val_acc:.4f}\")\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        for images, labels in loop:\n",
        "            # apply optional laplacian enhancement per-batch (on PIL would be earlier; here images are tensors)\n",
        "            # easier approach: apply laplacian on original files by using a custom dataset; we opt for simpler: skip per-batch.\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            if scaler is not None:\n",
        "                with autocast():\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += images.size(0)\n",
        "            loop.set_postfix(loss=running_loss/total, acc=100.*correct/total)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += images.size(0)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "        val_macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "        val_bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        history[\"epoch\"].append(epoch+1)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_macro_f1\"].append(val_macro_f1)\n",
        "        history[\"val_bal_acc\"].append(val_bal_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}% | Macro-F1: {val_macro_f1:.4f}, Bal Acc: {val_bal_acc:.4f}\")\n",
        "\n",
        "        # save best\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), str(best_model_path))\n",
        "            print(\"Saved best model:\", best_model_path)\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            print(f\"No improvement for {no_improve} epochs.\")\n",
        "\n",
        "        # early stop\n",
        "        if no_improve >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "        # save checkpoint\n",
        "        torch.save({\n",
        "            \"epoch\": epoch+1,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"history\": history,\n",
        "            \"best_val_acc\": best_val_acc\n",
        "        }, str(last_checkpoint_path))\n",
        "\n",
        "        # write csv\n",
        "        pd.DataFrame(history).to_csv(csv_log_path, index=False)\n",
        "\n",
        "    # load best weights\n",
        "    model.load_state_dict(best_wts)\n",
        "    print(\"Training complete. Best val acc:\", best_val_acc)\n",
        "    return {\n",
        "        \"model\": model,\n",
        "        \"history\": history,\n",
        "        \"save_dir\": save_dir,\n",
        "        \"val_acc\": best_val_acc,\n",
        "        \"classes\": classes,\n",
        "        \"val_loader\": val_loader,\n",
        "        \"test_dir\": test_dir\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXMuhVQgdxzg",
        "collapsed": true,
        "cellView": "form",
        "outputId": "f0cfd819-dd29-4887-a3ba-ecb109d8d01e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Starting training in /content/drive/MyDrive/synthbuster_runs/leave_one_out_dalle3 with MobileViTv2_100 ...\n",
            "Classes: ['ai', 'raise']\n",
            "Resuming from checkpoint: /content/drive/MyDrive/synthbuster_runs_checkpoints/leave_one_out_dalle3/last_checkpoint.pth\n",
            "Resumed at epoch 13, best_val_acc 92.7577\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/30 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 14/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [18:10<00:00, 33.04s/it, acc=99.1, loss=0.235]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 | Train Loss: 0.2353, Train Acc: 99.13% | Val Loss: 0.3681, Val Acc: 89.69% | Macro-F1: 0.8929, Bal Acc: 0.8862\n",
            "No improvement for 1 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 15/30 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 15/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [17:44<00:00, 32.26s/it, acc=99, loss=0.232]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 | Train Loss: 0.2325, Train Acc: 99.04% | Val Loss: 0.3518, Val Acc: 91.92% | Macro-F1: 0.9167, Bal Acc: 0.9112\n",
            "No improvement for 2 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 16/30 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 16/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [18:01<00:00, 32.78s/it, acc=99.4, loss=0.227]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 | Train Loss: 0.2274, Train Acc: 99.42% | Val Loss: 0.3510, Val Acc: 91.92% | Macro-F1: 0.9167, Bal Acc: 0.9112\n",
            "No improvement for 3 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 17/30 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 17/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [18:02<00:00, 32.80s/it, acc=99.2, loss=0.234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 | Train Loss: 0.2337, Train Acc: 99.23% | Val Loss: 0.3478, Val Acc: 91.64% | Macro-F1: 0.9138, Bal Acc: 0.9081\n",
            "No improvement for 4 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 18/30 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 18/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [17:43<00:00, 32.24s/it, acc=99.7, loss=0.226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 | Train Loss: 0.2260, Train Acc: 99.71% | Val Loss: 0.3519, Val Acc: 92.48% | Macro-F1: 0.9225, Bal Acc: 0.9168\n",
            "No improvement for 5 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 19/30 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 19/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [18:09<00:00, 33.01s/it, acc=99.6, loss=0.224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 | Train Loss: 0.2243, Train Acc: 99.62% | Val Loss: 0.3495, Val Acc: 92.20% | Macro-F1: 0.9197, Bal Acc: 0.9143\n",
            "No improvement for 6 epochs.\n",
            "Early stopping triggered.\n",
            "Training complete. Best val acc: 92.75766016713092\n"
          ]
        }
      ],
      "source": [
        "# @title (NOT RUN)\n",
        "# Now actually call the function\n",
        "result = train_one_run(\n",
        "    run_root=\"/content/drive/MyDrive/synthbuster_runs/leave_one_out_dalle3\",\n",
        "    image_size=256,\n",
        "    batch_size=32,\n",
        "    num_workers=2,\n",
        "    num_epochs=30,\n",
        "    laplacian_enhance=True,\n",
        "    save_dir_base=\"/content/drive/MyDrive/synthbuster_runs_checkpoints\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (RUN) â€œleave outâ€ one generator entirely from training and use it as unseen test data for Cross-Generator Generalization\n",
        "# Colab cell 6: run training for each held-out AI generator\n",
        "from pathlib import Path\n",
        "\n",
        "RUNS_DIR = Path(\"/content/drive/MyDrive/synthbuster_runs\")\n",
        "CHECKPOINTS_DIR = \"/content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints\"\n",
        "\n",
        "results = {}\n",
        "for held in ai_gens:\n",
        "    print(\"==== Starting run â€” held-out:\", held, \"====\")\n",
        "    run_root = RUNS_DIR / f\"leave_one_out_{held}\"\n",
        "    out = train_one_run(run_root,\n",
        "                        image_size=256,\n",
        "                        batch_size=32,\n",
        "                        num_workers=4,\n",
        "                        num_epochs=40,\n",
        "                        laplacian_enhance=False,  # set True to apply Laplacian preprocessing (requires custom dataset)\n",
        "                        save_dir_base=CHECKPOINTS_DIR)\n",
        "    results[held] = out\n",
        "    print(\"==== Finished run â€”\", held, \"best val acc:\", out['val_acc'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ad8c1bb2f2ef4d639d3623cfdb9543b4",
            "d249bd5ecb5646a5b55ff4fc5565f0e0",
            "e1b15829188a4fff80c5f030fdc9ee59",
            "edab9e85e0c2442bbe998a5a12f06312",
            "74414d11eb0c401a8506b3dd1030efaa",
            "be2e28eba05c456f8dad4995e1b6adf2",
            "a7df69c8cd5e44d7b82bb65baa9789f1",
            "25bafaafab7e4a008b1a28a333565708",
            "c98fd5a30981496fbd38e770dc16b85b",
            "5f82d2a3cfd649cdafc11006f912caaa",
            "6ffe1e3261f944b1a027f5fc9e8a92da"
          ]
        },
        "id": "8YnsfiCfJUA0",
        "outputId": "cee05415-9397-497d-98ff-846f2749fb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Starting run â€” held-out: dalle3 ====\n",
            "ðŸš€ Starting training in /content/drive/MyDrive/synthbuster_runs/leave_one_out_dalle3 with MobileViTv2_100 ...\n",
            "Classes: ['ai', 'raise']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/19.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad8c1bb2f2ef4d639d3623cfdb9543b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3510562111.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() if torch.cuda.is_available() else None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from checkpoint: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_dalle3/last_checkpoint.pth\n",
            "Resumed at epoch 12, best_val_acc 92.7577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 13/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 13/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [06:10<00:00, 11.23s/it, acc=99.3, loss=0.235]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/40 | Train Loss: 0.2351, Train Acc: 99.33% | Val Loss: 0.3486, Val Acc: 90.53% | Macro-F1: 0.9021, Bal Acc: 0.8962\n",
            "No improvement for 1 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 14/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 14/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:46<00:00, 10.51s/it, acc=99, loss=0.239]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/40 | Train Loss: 0.2390, Train Acc: 99.04% | Val Loss: 0.3366, Val Acc: 91.09% | Macro-F1: 0.9084, Bal Acc: 0.9037\n",
            "No improvement for 2 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 15/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 15/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:51<00:00, 10.66s/it, acc=99.6, loss=0.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/40 | Train Loss: 0.2303, Train Acc: 99.62% | Val Loss: 0.3288, Val Acc: 92.48% | Macro-F1: 0.9232, Bal Acc: 0.9199\n",
            "No improvement for 3 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 16/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 16/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:37<00:00, 10.22s/it, acc=99.6, loss=0.228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/40 | Train Loss: 0.2285, Train Acc: 99.62% | Val Loss: 0.3326, Val Acc: 91.92% | Macro-F1: 0.9172, Bal Acc: 0.9130\n",
            "No improvement for 4 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 17/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 17/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:37<00:00, 10.24s/it, acc=99.3, loss=0.236]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/40 | Train Loss: 0.2356, Train Acc: 99.33% | Val Loss: 0.3295, Val Acc: 91.64% | Macro-F1: 0.9147, Bal Acc: 0.9118\n",
            "No improvement for 5 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 18/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 18/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:58<00:00, 10.87s/it, acc=99.7, loss=0.229]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/40 | Train Loss: 0.2291, Train Acc: 99.71% | Val Loss: 0.3318, Val Acc: 91.09% | Macro-F1: 0.9084, Bal Acc: 0.9037\n",
            "No improvement for 6 epochs.\n",
            "Early stopping triggered.\n",
            "Training complete. Best val acc: 92.75766016713092\n",
            "==== Finished run â€” dalle3 best val acc: 92.75766016713092\n",
            "==== Starting run â€” held-out: firefly ====\n",
            "ðŸš€ Starting training in /content/drive/MyDrive/synthbuster_runs/leave_one_out_firefly with MobileViTv2_100 ...\n",
            "Classes: ['ai', 'raise']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() if torch.cuda.is_available() else None\n",
            "Epoch 1/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [06:25<00:00, 11.69s/it, acc=57.1, loss=0.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 | Train Loss: 0.6802, Train Acc: 57.12% | Val Loss: 0.6550, Val Acc: 67.13% | Macro-F1: 0.6634, Bal Acc: 0.6625\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_firefly/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 2/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:56<00:00, 10.80s/it, acc=78.9, loss=0.604]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/40 | Train Loss: 0.6044, Train Acc: 78.94% | Val Loss: 0.6061, Val Acc: 75.49% | Macro-F1: 0.7460, Bal Acc: 0.7434\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_firefly/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 3/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:48<00:00, 10.57s/it, acc=84.9, loss=0.512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/40 | Train Loss: 0.5123, Train Acc: 84.90% | Val Loss: 0.5515, Val Acc: 77.99% | Macro-F1: 0.7722, Bal Acc: 0.7690\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_firefly/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 4/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 4/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:59<00:00, 10.90s/it, acc=91.3, loss=0.392]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/40 | Train Loss: 0.3919, Train Acc: 91.35% | Val Loss: 0.5063, Val Acc: 81.06% | Macro-F1: 0.8046, Bal Acc: 0.8010\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_firefly/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 5/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [06:22<00:00, 11.58s/it, acc=92.8, loss=0.325]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/40 | Train Loss: 0.3252, Train Acc: 92.79% | Val Loss: 0.4785, Val Acc: 82.73% | Macro-F1: 0.8211, Bal Acc: 0.8167\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_firefly/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 6/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 6/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:55<00:00, 10.78s/it, acc=95, loss=0.288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/40 | Train Loss: 0.2885, Train Acc: 95.00% | Val Loss: 0.5006, Val Acc: 80.78% | Macro-F1: 0.7943, Bal Acc: 0.7893\n",
            "No improvement for 1 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 7/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 7/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [06:01<00:00, 10.95s/it, acc=96.3, loss=0.282]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/40 | Train Loss: 0.2817, Train Acc: 96.35% | Val Loss: 0.5045, Val Acc: 80.78% | Macro-F1: 0.7930, Bal Acc: 0.7880\n",
            "No improvement for 2 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 8/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 8/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:56<00:00, 10.80s/it, acc=98.5, loss=0.255]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/40 | Train Loss: 0.2546, Train Acc: 98.46% | Val Loss: 0.4917, Val Acc: 81.06% | Macro-F1: 0.7988, Bal Acc: 0.7936\n",
            "No improvement for 3 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 9/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 9/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:50<00:00, 10.61s/it, acc=98.5, loss=0.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/40 | Train Loss: 0.2495, Train Acc: 98.46% | Val Loss: 0.5057, Val Acc: 81.06% | Macro-F1: 0.7970, Bal Acc: 0.7918\n",
            "No improvement for 4 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 10/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 10/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [06:00<00:00, 10.91s/it, acc=98.8, loss=0.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/40 | Train Loss: 0.2405, Train Acc: 98.75% | Val Loss: 0.5343, Val Acc: 79.94% | Macro-F1: 0.7822, Bal Acc: 0.7781\n",
            "No improvement for 5 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 11/40 [Train]:   0%|          | 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 11/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [05:53<00:00, 10.71s/it, acc=99.3, loss=0.231]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/40 | Train Loss: 0.2314, Train Acc: 99.33% | Val Loss: 0.5358, Val Acc: 80.22% | Macro-F1: 0.7849, Bal Acc: 0.7806\n",
            "No improvement for 6 epochs.\n",
            "Early stopping triggered.\n",
            "Training complete. Best val acc: 82.72980501392757\n",
            "==== Finished run â€” firefly best val acc: 82.72980501392757\n",
            "==== Starting run â€” held-out: stable-diffusion-xl ====\n",
            "ðŸš€ Starting training in /content/drive/MyDrive/synthbuster_runs/leave_one_out_stable-diffusion-xl with MobileViTv2_100 ...\n",
            "Classes: ['ai', 'raise']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:83: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() if torch.cuda.is_available() else None\n",
            "Epoch 1/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 1/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:57<00:00, 11.91s/it, acc=68, loss=0.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40 | Train Loss: 0.6500, Train Acc: 68.02% | Val Loss: 0.6606, Val Acc: 62.41% | Macro-F1: 0.6188, Bal Acc: 0.6408\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_stable-diffusion-xl/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 2/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:38<00:00, 11.29s/it, acc=82.4, loss=0.569]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/40 | Train Loss: 0.5687, Train Acc: 82.40% | Val Loss: 0.6143, Val Acc: 69.25% | Macro-F1: 0.6912, Bal Acc: 0.7046\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_stable-diffusion-xl/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 3/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:16<00:00, 10.56s/it, acc=84.7, loss=0.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/40 | Train Loss: 0.4997, Train Acc: 84.69% | Val Loss: 0.5750, Val Acc: 72.21% | Macro-F1: 0.7189, Bal Acc: 0.7385\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_stable-diffusion-xl/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 4/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 4/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:41<00:00, 11.38s/it, acc=88.5, loss=0.426]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/40 | Train Loss: 0.4262, Train Acc: 88.54% | Val Loss: 0.5131, Val Acc: 77.90% | Macro-F1: 0.7788, Bal Acc: 0.7889\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_stable-diffusion-xl/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 5/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:15<00:00, 10.52s/it, acc=91.2, loss=0.363]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/40 | Train Loss: 0.3629, Train Acc: 91.25% | Val Loss: 0.5094, Val Acc: 77.68% | Macro-F1: 0.7753, Bal Acc: 0.7911\n",
            "No improvement for 1 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 6/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 6/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:40<00:00, 11.34s/it, acc=96.6, loss=0.298]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/40 | Train Loss: 0.2977, Train Acc: 96.56% | Val Loss: 0.4873, Val Acc: 78.82% | Macro-F1: 0.7873, Bal Acc: 0.8011\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_stable-diffusion-xl/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 7/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 7/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:22<00:00, 10.75s/it, acc=96.9, loss=0.275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/40 | Train Loss: 0.2754, Train Acc: 96.88% | Val Loss: 0.4999, Val Acc: 78.82% | Macro-F1: 0.7869, Bal Acc: 0.8024\n",
            "No improvement for 1 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 8/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 8/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:33<00:00, 11.11s/it, acc=98.2, loss=0.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/40 | Train Loss: 0.2596, Train Acc: 98.23% | Val Loss: 0.5216, Val Acc: 78.36% | Macro-F1: 0.7818, Bal Acc: 0.7991\n",
            "No improvement for 2 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 9/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 9/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:46<00:00, 11.55s/it, acc=98.4, loss=0.247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/40 | Train Loss: 0.2475, Train Acc: 98.44% | Val Loss: 0.5183, Val Acc: 78.36% | Macro-F1: 0.7820, Bal Acc: 0.7986\n",
            "No improvement for 3 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 10/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 10/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:46<00:00, 11.54s/it, acc=99.1, loss=0.245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/40 | Train Loss: 0.2451, Train Acc: 99.06% | Val Loss: 0.5044, Val Acc: 79.95% | Macro-F1: 0.7984, Bal Acc: 0.8137\n",
            "Saved best model: /content/drive/MyDrive/synthbuster_runs/synthbuster_runs_checkpoints/leave_one_out_stable-diffusion-xl/best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 11/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 11/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:17<00:00, 10.59s/it, acc=98.6, loss=0.247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/40 | Train Loss: 0.2470, Train Acc: 98.65% | Val Loss: 0.5548, Val Acc: 75.85% | Macro-F1: 0.7547, Bal Acc: 0.7770\n",
            "No improvement for 1 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 12/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 12/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:31<00:00, 11.06s/it, acc=99.6, loss=0.231]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/40 | Train Loss: 0.2306, Train Acc: 99.58% | Val Loss: 0.5446, Val Acc: 76.99% | Macro-F1: 0.7671, Bal Acc: 0.7870\n",
            "No improvement for 2 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 13/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 13/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [05:32<00:00, 11.08s/it, acc=99, loss=0.239]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/40 | Train Loss: 0.2386, Train Acc: 98.96% | Val Loss: 0.5539, Val Acc: 76.54% | Macro-F1: 0.7623, Bal Acc: 0.7828\n",
            "No improvement for 3 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 14/40 [Train]:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3510562111.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Epoch 14/40 [Train]:  27%|â–ˆâ–ˆâ–‹       | 8/30 [01:32<02:47,  7.64s/it, acc=100, loss=0.23]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUGSc0lhOpHiRMgmP0n39E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad8c1bb2f2ef4d639d3623cfdb9543b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d249bd5ecb5646a5b55ff4fc5565f0e0",
              "IPY_MODEL_e1b15829188a4fff80c5f030fdc9ee59",
              "IPY_MODEL_edab9e85e0c2442bbe998a5a12f06312"
            ],
            "layout": "IPY_MODEL_74414d11eb0c401a8506b3dd1030efaa"
          }
        },
        "d249bd5ecb5646a5b55ff4fc5565f0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2e28eba05c456f8dad4995e1b6adf2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a7df69c8cd5e44d7b82bb65baa9789f1",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "e1b15829188a4fff80c5f030fdc9ee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25bafaafab7e4a008b1a28a333565708",
            "max": 19697308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c98fd5a30981496fbd38e770dc16b85b",
            "value": 19697308
          }
        },
        "edab9e85e0c2442bbe998a5a12f06312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f82d2a3cfd649cdafc11006f912caaa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6ffe1e3261f944b1a027f5fc9e8a92da",
            "value": "â€‡19.7M/19.7Mâ€‡[00:00&lt;00:00,â€‡21.8MB/s]"
          }
        },
        "74414d11eb0c401a8506b3dd1030efaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2e28eba05c456f8dad4995e1b6adf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7df69c8cd5e44d7b82bb65baa9789f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25bafaafab7e4a008b1a28a333565708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98fd5a30981496fbd38e770dc16b85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f82d2a3cfd649cdafc11006f912caaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ffe1e3261f944b1a027f5fc9e8a92da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}