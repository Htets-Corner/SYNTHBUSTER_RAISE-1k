{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEy9QmYy0QGSqHSioKlJn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Htets-Corner/SYNTHBUSTER_RAISE-1k/blob/main/synthbuster_real.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Mount Drive and Import Libraries\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import core libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Torch and torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# Utilities\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPUt4nI_75-U",
        "outputId": "36d0bd1f-441b-409e-f7c3-ce40cb85aee1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Prepare dataset loaders and save structured dataset into Drive (resumable)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths to original datasets in your Drive\n",
        "real_path = \"/content/drive/MyDrive/RAISE/PNG\"\n",
        "ai_path = \"/content/drive/MyDrive/SYNTHBUSTER_32\"\n",
        "\n",
        "# Destination structured dataset root (inside Drive)\n",
        "dataset_root = \"/content/drive/MyDrive/Binary_Dataset\"\n",
        "train_dir = os.path.join(dataset_root, \"train\")\n",
        "test_dir = os.path.join(dataset_root, \"test\")\n",
        "\n",
        "# Create folders\n",
        "for split in [\"train\", \"test\"]:\n",
        "    for cls in [\"real\", \"ai\"]:\n",
        "        os.makedirs(os.path.join(dataset_root, split, cls), exist_ok=True)\n",
        "\n",
        "# --- Handle real dataset (flat folder of PNGs) ---\n",
        "real_images = os.listdir(real_path)\n",
        "random.shuffle(real_images)\n",
        "\n",
        "split_idx = int(0.8 * len(real_images))\n",
        "train_real, test_real = real_images[:split_idx], real_images[split_idx:]\n",
        "\n",
        "# Copy real train images (skip if exists)\n",
        "for img in tqdm(train_real, desc=\"Copying Real Train\"):\n",
        "    dst = os.path.join(train_dir, \"real\", img)\n",
        "    if not os.path.exists(dst):\n",
        "        shutil.copy(os.path.join(real_path, img), dst)\n",
        "\n",
        "# Copy real test images (skip if exists)\n",
        "for img in tqdm(test_real, desc=\"Copying Real Test\"):\n",
        "    dst = os.path.join(test_dir, \"real\", img)\n",
        "    if not os.path.exists(dst):\n",
        "        shutil.copy(os.path.join(real_path, img), dst)\n",
        "\n",
        "# --- Handle AI dataset (9 subfolders with JPGs) ---\n",
        "ai_folders = [os.path.join(ai_path, f) for f in os.listdir(ai_path) if os.path.isdir(os.path.join(ai_path, f))]\n",
        "ai_images = []\n",
        "for folder in ai_folders:\n",
        "    imgs = [os.path.join(folder, x) for x in os.listdir(folder)]\n",
        "    ai_images.extend(imgs)\n",
        "\n",
        "random.shuffle(ai_images)\n",
        "\n",
        "split_idx = int(0.8 * len(ai_images))\n",
        "train_ai, test_ai = ai_images[:split_idx], ai_images[split_idx:]\n",
        "\n",
        "# Copy AI train images (skip if exists)\n",
        "for img in tqdm(train_ai, desc=\"Copying AI Train\"):\n",
        "    dst = os.path.join(train_dir, \"ai\", os.path.basename(img))\n",
        "    if not os.path.exists(dst):\n",
        "        shutil.copy(img, dst)\n",
        "\n",
        "# Copy AI test images (skip if exists)\n",
        "for img in tqdm(test_ai, desc=\"Copying AI Test\"):\n",
        "    dst = os.path.join(test_dir, \"ai\", os.path.basename(img))\n",
        "    if not os.path.exists(dst):\n",
        "        shutil.copy(img, dst)\n",
        "\n",
        "print(\"✅ Dataset structured successfully and saved in Google Drive at:\", dataset_root)\n",
        "\n",
        "# --- Define transforms ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# --- Create datasets & loaders ---\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train set size: {len(train_dataset)} images\")\n",
        "print(f\"Test set size: {len(test_dataset)} images\")\n",
        "print(f\"Classes: {train_dataset.classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg6IgkxbHAkR",
        "outputId": "7acda174-8838-4392-fcb9-b6681a7c96d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying Real Train: 100%|██████████| 799/799 [10:00<00:00,  1.33it/s]\n",
            "Copying Real Test: 100%|██████████| 200/200 [02:37<00:00,  1.27it/s]\n",
            "Copying AI Train: 100%|██████████| 7200/7200 [06:41<00:00, 17.93it/s]  \n",
            "Copying AI Test: 100%|██████████| 1800/1800 [05:53<00:00,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset structured successfully and saved in Google Drive at: /content/drive/MyDrive/Binary_Dataset\n",
            "Train set size: 1799 images\n",
            "Test set size: 1071 images\n",
            "Classes: ['ai', 'real']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define MobileNetV2 model for Binary Classification\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load pretrained MobileNetV2\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Freeze feature extractor (optional, speeds up training if dataset is small)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace classifier for binary classification\n",
        "model.classifier[1] = nn.Linear(model.last_channel, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"✅ MobileNetV2 ready for binary classification (real vs AI)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2hDII49Qciy",
        "outputId": "d5d5db97-88e0-4d8f-d3da-35e171e435c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 35.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MobileNetV2 ready for binary classification (real vs AI)\n"
          ]
        }
      ]
    }
  ]
}